# ################################
# Ultimate MSP-PODCAST Discrete SSL Training Configuration
# Supports: WavLM, HuBERT, Wav2Vec2
# Optimized for emotion recognition with proper vocoder mapping
# ################################

# Discrete SSL + ECAPA-TDNN with hybrid attention
seed: 42
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Results folder
output_folder: !ref results/MSP_PODCAST/ultimate_discrete_ssl/<ssl_model_type>/<attention_mode>/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt

### SSL Model Configuration (Based on DASB best practices)
# Recommended: wavlm (best performance according to DASB)
ssl_model_type: wavlm  # Options: hubert, wavlm, wav2vec2

# SSL model hub configurations
ssl_hubs:
    wavlm: microsoft/wavlm-large
    hubert: facebook/hubert-large-ll60k  
    wav2vec2: facebook/wav2vec2-large-960h-lv60-self

# Dynamic SSL hub selection
ssl_hub: !apply:speechbrain.utils.hparams.choice
    value: !ref <ssl_model_type>
    choices: !ref <ssl_hubs>

ssl_folder: !ref <save_folder>/ssl_checkpoint

# K-means and vocoder configurations for each SSL type
vocoder_configs:
    wavlm: 
        vocoder_repo_id: speechbrain/hifigan-wavlm-l1-3-7-12-18-23-k1000-LibriTTS
        kmeans_dataset: LibriSpeech
        ssl_layers: [1, 3, 7, 12, 18, 23]
    hubert: 
        vocoder_repo_id: speechbrain/hifigan-hubert-k1000-LibriTTS
        kmeans_dataset: LibriSpeech  
        ssl_layers: [7, 23]
    wav2vec2: 
        vocoder_repo_id: speechbrain/hifigan-wav2vec-l1-3-7-12-18-23-k1000-LibriTTS
        kmeans_dataset: LibriSpeech
        ssl_layers: [1, 3, 7, 12, 18, 23]

# K-means cache directory
kmeans_cache_dir: !ref <save_folder>/kmeans_cache

# SSL settings
freeze_ssl: True
freeze_feature_extractor: True
num_codebooks: 6  # Number of codebooks/layers
num_clusters: 1000  # K-means clusters

# Static configurations for each SSL type (will be selected dynamically)
# WavLM configuration
wavlm_vocoder_repo_id: speechbrain/hifigan-wavlm-k1000-LibriTTS
wavlm_kmeans_dataset: LibriSpeech
wavlm_ssl_layers: [1, 3, 7, 12, 18, 23]

# HuBERT configuration  
hubert_vocoder_repo_id: speechbrain/hifigan-hubert-k1000-LibriTTS
hubert_kmeans_dataset: LibriSpeech
hubert_ssl_layers: [7, 23]

# Wav2Vec2 configuration
wav2vec2_vocoder_repo_id: speechbrain/hifigan-wav2vec-l1-3-7-12-18-23-k1000-LibriTTS
wav2vec2_kmeans_dataset: LibriSpeech
wav2vec2_ssl_layers: [1, 3, 7, 12, 18, 23]

# Dynamic selection based on ssl_model_type
kmeans_dataset: !apply:speechbrain.utils.hparams.choice
    value: !ref <ssl_model_type>
    choices:
        wavlm: !ref <wavlm_kmeans_dataset>
        hubert: !ref <hubert_kmeans_dataset>
        wav2vec2: !ref <wav2vec2_kmeans_dataset>

ssl_layer_num: !apply:speechbrain.utils.hparams.choice
    value: !ref <ssl_model_type>
    choices:
        wavlm: !ref <wavlm_ssl_layers>
        hubert: !ref <hubert_ssl_layers>
        wav2vec2: !ref <wav2vec2_ssl_layers>

vocoder_repo_id: !apply:speechbrain.utils.hparams.choice
    value: !ref <ssl_model_type>
    choices:
        wavlm: !ref <wavlm_vocoder_repo_id>
        hubert: !ref <hubert_vocoder_repo_id>
        wav2vec2: !ref <wav2vec2_vocoder_repo_id>

# Attention mode configuration
attention_mode: iemocap  # Options: iemocap, dasb, custom

### Model Architecture Configuration
batch_size: 8  # Adjust based on GPU memory
# Ultimate Model Settings
emb_dim: 1024
use_positional_encoding: True   # Enhanced temporal modeling
dropout: 0.15
activation: !name:torch.nn.LeakyReLU

# Training Configuration
number_of_epochs: 20
base_lr: 0.0005
max_lr: 0.001
step_size: 65000

# Sample rate
sample_rate: 16000

# Multi-class evaluation metrics configuration
eval_metrics:
    primary_metric: 'macro_f1'        # Primary metric for model selection
    secondary_metrics: ['accuracy', 'weighted_f1', 'precision_macro', 'recall_macro']
    
# Class weighting for imbalanced classes (optional)
use_class_weights: False
class_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  # 10 MSP-PODCAST classes

# Data folders and files
data_folder: !PLACEHOLDER  # Will be set via command line

# MSP-PODCAST 10-class annotations - 修复路径
train_annotation: ../msp_train_10class.json
valid_annotation: ../msp_valid_10class.json
test_annotation: ../msp_test_10class.json

# Dataloader options
train_dataloader_opts:
    batch_size: !ref <batch_size>
    shuffle: True
    num_workers: 4

valid_dataloader_opts:
    batch_size: !ref <batch_size>
    shuffle: False
    num_workers: 4

test_dataloader_opts:
    batch_size: !ref <batch_size>
    shuffle: False
    num_workers: 4

# Model selection based on SSL type
ssl_model: !apply:speechbrain.utils.hparams.choice
    value: !ref <ssl_model_type>
    choices:
        wavlm: !new:speechbrain.lobes.models.huggingface_transformers.wavlm.WavLM
            source: !ref <ssl_hub>
            output_norm: True
            freeze: !ref <freeze_ssl>
            freeze_feature_extractor: !ref <freeze_feature_extractor>
            output_all_hiddens: True
            save_path: !ref <ssl_folder>
        hubert: !new:speechbrain.lobes.models.huggingface_transformers.hubert.HuBERT
            source: !ref <ssl_hub>
            output_norm: True
            freeze: !ref <freeze_ssl>
            freeze_feature_extractor: !ref <freeze_feature_extractor>
            output_all_hiddens: True
            save_path: !ref <ssl_folder>
        wav2vec2: !new:speechbrain.lobes.models.huggingface_transformers.wav2vec2.Wav2Vec2
            source: !ref <ssl_hub>
            output_norm: True
            freeze: !ref <freeze_ssl>
            freeze_feature_extractor: !ref <freeze_feature_extractor>
            output_all_hiddens: True
            save_path: !ref <ssl_folder>

# 暂时注释掉 DiscreteSSL，先测试基础SSL模型
# Discrete SSL Codec - 暂时禁用进行测试
# codec: !new:speechbrain.lobes.models.huggingface_transformers.discrete_ssl.DiscreteSSL
#     save_path: !ref <kmeans_cache_dir>
#     ssl_model: !ref <ssl_model>
#     kmeans_dataset: !ref <kmeans_dataset>
#     num_clusters: !ref <num_clusters>
#     kmeans_repo_id: speechbrain/SSL_Quantization

# 简化的embedding层配置，直接使用SSL特征
ssl_embedding_layer: !new:speechbrain.nnet.linear.Linear
    input_size: 1024  # WavLM输出维度
    n_neurons: !ref <emb_dim>

# Ultimate Discrete Embedding (暂时简化)
# discrete_embedding_layer: !new:custom_model.Discrete_EmbeddingLayer
#     num_codebooks: !ref <num_codebooks>
#     vocab_size: !ref <num_clusters>
#     emb_dim: !ref <emb_dim>
#     pad_idx: 0
#     use_positional_encoding: !ref <use_positional_encoding>
#     dropout: !ref <dropout>

# 简化版本：直接处理SSL特征
feature_projection: !new:speechbrain.nnet.linear.Linear
    input_size: 1024  # WavLM hidden size
    n_neurons: !ref <emb_dim>

# Ultimate Attention MLP (暂时移除，避免参数不匹配)
# attention_mlp: !new:custom_model.AttentionMLP
#     input_dim: !ref <emb_dim>
#     hidden_dim: 128
#     output_dim: 1
#     num_codebooks: !ref <num_codebooks>
#     dropout: !ref <dropout>
#     activation: !ref <activation>

# ECAPA-TDNN encoder
embedding_model: !new:speechbrain.lobes.models.ECAPA_TDNN.ECAPA_TDNN
    input_size: !ref <emb_dim>
    channels: [1024, 1024, 1024, 1024, 3072]
    kernel_sizes: [5, 3, 3, 3, 1]
    dilations: [1, 2, 3, 4, 1]
    attention_channels: 128
    lin_neurons: 192

# Classifier
classifier: !new:speechbrain.lobes.models.ECAPA_TDNN.Classifier
    input_size: 192
    out_neurons: 10  # MSP-PODCAST 10 classes

# Ultimate model combination - 修复模块类型错误
modules:
    ssl_model: !ref <ssl_model>
    feature_projection: !ref <feature_projection>
    embedding_model: !ref <embedding_model>
    classifier: !ref <classifier>

# Ultimate model for optimization - 修复 list 不是 Module 的错误
model: !ref <embedding_model>  # 只使用主要的embedding模型进行优化

# Loss and metrics
log_softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

compute_cost: !name:speechbrain.nnet.losses.nll_loss

# Enhanced multi-class error computation
error_stats: !name:custom_model.MultiClassMetrics
    primary_metric: !ref <eval_metrics>[primary_metric]
    secondary_metrics: !ref <eval_metrics>[secondary_metrics]

# Optimizer
opt_class: !name:torch.optim.Adam
lr: !ref <base_lr>

model_opt_class: !name:torch.optim.Adam
    lr: !ref <base_lr>

# Learning rate scheduling - 修复参数兼容性
lr_annealing_model: !new:speechbrain.nnet.schedulers.ReduceLROnPlateau
    factor: 0.8
    patience: 3
    # min_lr: 0.00001  # 移除不兼容的参数

# Learning rate scheduling configuration
lr_scheduling_metric: 'primary_metric'  # Use primary metric for LR scheduling
lr_scheduling_mode: 'max'  # For metrics like macro_f1 that should be maximized

# Epoch counter
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

# Checkpointer
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        model: !ref <model>
        scheduler_model: !ref <lr_annealing_model>
        counter: !ref <epoch_counter>

# Logger
train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>

# Tokenizer config for codec (if needed)
tokenizer_config:
    deduplicate: [False, True, False, True, False, True]  # Per layer deduplication
    bpe_tokenizers: [null, null, null, null, null, null]  # No BPE tokenizers

### Quick switching between SSL models ###
# To use HuBERT: --ssl_model_type=hubert
# To use Wav2Vec2: --ssl_model_type=wav2vec2  
# To use WavLM: --ssl_model_type=wavlm (default)

### Training Examples ###
# WavLM training:
# python train_discrete_SSL.py hparams/train_discrete_SSL.yaml --ssl_model_type=wavlm --data_folder=/path/to/data

# HuBERT training:  
# python train_discrete_SSL.py hparams/train_discrete_SSL.yaml --ssl_model_type=hubert --data_folder=/path/to/data

# Wav2Vec2 training:
# python train_discrete_SSL.py hparams/train_discrete_SSL.yaml --ssl_model_type=wav2vec2 --data_folder=/path/to/data