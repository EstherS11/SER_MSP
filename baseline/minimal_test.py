#!/usr/bin/env python3
# minimal_test.py - è¶…çº§ç®€å•çš„æµ‹è¯•è„šæœ¬

import json
import os
import random
from pathlib import Path

# ä½ çš„æ•°æ®è·¯å¾„
DATA_ROOT = "/data/user_data/esthers/SER_MSP"

def create_tiny_dataset():
    """åˆ›å»ºè¶…å°æ•°æ®é›†ï¼šæ¯ä¸ªé›†åˆåªæœ‰10ä¸ªæ ·æœ¬"""
    
    print("ğŸ¯ Creating tiny test dataset...")
    
    emotion_map = {'N': 0, 'H': 1, 'S': 2, 'A': 3, 'F': 4, 'D': 5, 'U': 6, 'C': 7, 'O': 8, 'X': 9}
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("tiny_data")
    output_dir.mkdir(exist_ok=True)
    
    # å¤„ç†æ¯ä¸ªsplitï¼Œæ¯ä¸ªåªå–10ä¸ªæ ·æœ¬
    for split in ['train', 'valid', 'test']:
        json_file = f"{DATA_ROOT}/msp_{split}_10class.json"
        
        print(f"Processing {split}...")
        
        with open(json_file, 'r') as f:
            full_data = json.load(f)
        
        # éšæœºé€‰æ‹©10ä¸ªæ ·æœ¬
        all_items = list(full_data.items())
        selected = random.sample(all_items, min(10, len(all_items)))
        
        # åˆ›å»ºç›®å½•
        split_dir = output_dir / split
        split_dir.mkdir(exist_ok=True)
        
        # å†™å…¥æ–‡ä»¶
        with open(split_dir / "speech.scp", 'w') as scp_f, \
             open(split_dir / "emotion.txt", 'w') as emo_f:
            
            for utt_id, info in selected:
                wav_path = info['wav']
                emotion = info['emo']
                
                if os.path.exists(wav_path) and emotion in emotion_map:
                    scp_f.write(f"{utt_id} {wav_path}\\n")
                    emo_f.write(f"{utt_id} {emotion_map[emotion]}\\n")
        
        print(f"âœ… {split}: 10 samples")
    
    print("âœ… Tiny dataset created!")

def create_minimal_config():
    """åˆ›å»ºæœ€ç®€é…ç½®ï¼š1ä¸ªepochï¼Œæœ€å°å‚æ•°"""
    
    config = '''# minimal_config.yaml
batch_type: numel
batch_size: 2
max_epoch: 1
patience: 1
seed: 42
num_workers: 1
log_interval_steps: 1

optim: adam
optim_conf:
  lr: 0.01

model: espnet_ser
model_conf:
  num_class: 10

preprocessor: default
preprocessor_conf: {}

best_model_criterion:
  - ["valid", "acc", "max"]

resume: false
keep_nbest_models: 1
use_tensorboard: false
'''
    
    with open("minimal_config.yaml", 'w') as f:
        f.write(config)
    
    print("âœ… Minimal config created!")

def run_minimal_test():
    """è¿è¡Œæœ€å°æµ‹è¯•"""
    
    import subprocess
    import sys
    
    print("ğŸš€ Running minimal test...")
    
    cmd = [
        sys.executable, "-m", "espnet2.bin.ser_train",
        "--use_preprocessor", "true",
        "--train_data_path_and_name_and_type", "tiny_data/train/speech.scp,speech,sound",
        "--train_data_path_and_name_and_type", "tiny_data/train/emotion.txt,emotion,text",
        "--valid_data_path_and_name_and_type", "tiny_data/valid/speech.scp,speech,sound",
        "--valid_data_path_and_name_and_type", "tiny_data/valid/emotion.txt,emotion,text",
        "--output_dir", "exp/minimal_test",
        "--config", "minimal_config.yaml",
        "--ngpu", "1",
    ]
    
    print("Command:", " ".join(cmd))
    print("Expected time: 2-5 minutes")
    
    try:
        subprocess.run(cmd, check=True)
        print("âœ… Minimal test PASSED!")
        return True
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return False

def main():
    print("âš¡ Super Minimal ESP-net Test")
    print("=" * 30)
    print("ğŸ“Š Data: 10 samples per split")
    print("â±ï¸  Time: ~2-5 minutes")
    print("ğŸ¯ Goal: Check if ESP-net works")
    print("=" * 30)
    
    random.seed(42)
    
    # 1. åˆ›å»ºè¶…å°æ•°æ®é›†
    create_tiny_dataset()
    
    # 2. åˆ›å»ºæœ€ç®€é…ç½®
    create_minimal_config()
    
    # 3. è¿è¡Œæµ‹è¯•
    if run_minimal_test():
        print("\\nğŸ‰ SUCCESS! ESP-net pipeline works!")
        print("ğŸš€ You can now run the full training")
    else:
        print("\\nâŒ Something is wrong with the setup")
        print("ğŸ”§ Check the error messages above")

if __name__ == "__main__":
    main()