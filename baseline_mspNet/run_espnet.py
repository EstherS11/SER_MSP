#!/usr/bin/env python3
import argparse
import subprocess
import sys
import os
from pathlib import Path

def prepare_espnet_data(baseline_dir, output_dir="data"):
    """å‡†å¤‡ESP-netæ ¼å¼æ•°æ®"""
    # æ£€æŸ¥æ˜¯å¦æœ‰data_prep.pyæ–‡ä»¶
    data_prep_file = Path("data_prep.py")
    if data_prep_file.exists():
        from data_prep import prepare_msp_data
        return prepare_msp_data(baseline_dir, output_dir)
    else:
        # å¦‚æœæ²¡æœ‰ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®å‡†å¤‡å‡½æ•°
        print("âš ï¸  data_prep.py not found, creating basic data preparation...")
        create_basic_data_prep()
        from data_prep import prepare_msp_data
        return prepare_msp_data(baseline_dir, output_dir)

def create_basic_data_prep():
    """åˆ›å»ºåŸºæœ¬çš„æ•°æ®å‡†å¤‡è„šæœ¬"""
    basic_data_prep = '''#!/usr/bin/env python3
# data_prep.py - åŸºæœ¬æ•°æ®å‡†å¤‡è„šæœ¬

import json
import os
from pathlib import Path

def prepare_msp_data(baseline_dir, output_dir="data"):
    """å‡†å¤‡MSP-PODCASTæ•°æ®"""
    print(f"ğŸ”§ Preparing data from {baseline_dir} to {output_dir}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®ç»“æ„å®ç°
    # ç°åœ¨åªåˆ›å»ºç›®å½•ç»“æ„
    for split in ["train", "valid", "test"]:
        split_dir = output_path / split
        split_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºç©ºæ–‡ä»¶ä½œä¸ºå ä½ç¬¦
        (split_dir / "speech.scp").touch()
        (split_dir / "emotion.txt").touch()
        (split_dir / "utt2spk").touch()
    
    print(f"âœ… Basic data structure created in {output_dir}")
    return True

if __name__ == "__main__":
    prepare_msp_data("./baseline")
'''
    
    with open("data_prep.py", 'w') as f:
        f.write(basic_data_prep)
    
    print("âœ… Created basic data_prep.py")

def ensure_scripts_exist():
    """ç¡®ä¿å¿…è¦çš„è„šæœ¬å­˜åœ¨"""
    # ç¡®ä¿æ³¨å†Œè„šæœ¬å·²è¿è¡Œ
    register_script = Path("register_model.py")
    ser_train_script = Path("ser_train.py")
    
    if not ser_train_script.exists():
        print("ğŸ”§ Running model registration...")
        if register_script.exists():
            subprocess.run([sys.executable, "register_model.py"], check=True)
        else:
            print("âŒ register_model.py not found!")
            return False
    
    return True

def run_espnet_training():
    """è¿è¡ŒESP-netè®­ç»ƒ"""
    
    data_dir = Path("data")
    exp_dir = Path("exp/wavlm_ecapa_baseline")
    config_file = "train_config.yaml"
    
    # æ£€æŸ¥æ•°æ®
    for split in ["train", "valid"]:
        speech_scp = data_dir / split / "speech.scp"
        emotion_txt = data_dir / split / "emotion.txt"
        
        if not speech_scp.exists() or not emotion_txt.exists():
            print(f"âŒ {split} data files not found")
            print("Please run data preparation first")
            return False
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
        if speech_scp.stat().st_size == 0 or emotion_txt.stat().st_size == 0:
            print(f"âš ï¸  {split} data files are empty")
            print("Please check your data preparation")
    
    # ç¡®ä¿è„šæœ¬å­˜åœ¨
    if not ensure_scripts_exist():
        return False
    
    # åˆ›å»ºå®éªŒç›®å½•
    exp_dir.mkdir(parents=True, exist_ok=True)
    
    # ESP-netè®­ç»ƒå‘½ä»¤ - ä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„è®­ç»ƒè„šæœ¬
    train_cmd = [
        sys.executable, "ser_train.py",
        "--config", config_file,
        "--train_data_path_and_name_and_type", f"{data_dir}/train/speech.scp,speech,sound",
        "--train_data_path_and_name_and_type", f"{data_dir}/train/emotion.txt,emotion,text",
        "--valid_data_path_and_name_and_type", f"{data_dir}/valid/speech.scp,speech,sound", 
        "--valid_data_path_and_name_and_type", f"{data_dir}/valid/emotion.txt,emotion,text",
        "--output_dir", str(exp_dir),
        "--ngpu", "1",
        "--num_workers", "4",
        "--use_preprocessor", "true",
    ]
    
    print("ğŸš€ Starting ESP-net training...")
    print("Command:", " ".join(train_cmd))
    print()
    
    try:
        result = subprocess.run(train_cmd, check=True, capture_output=False)
        print("âœ… Training completed successfully!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ Training failed with exit code {e.returncode}")
        return False
    except FileNotFoundError as e:
        print(f"âŒ Script not found: {e}")
        print("Please make sure ser_train.py exists and is executable")
        return False

def run_espnet_evaluation():
    """è¿è¡ŒESP-netè¯„ä¼°"""
    
    data_dir = Path("data")
    exp_dir = Path("exp/wavlm_ecapa_baseline")
    
    # æ‰¾æœ€ä½³æ¨¡å‹
    model_files = [
        exp_dir / "valid.macro_f1.best.pth",
        exp_dir / "valid.acc.best.pth", 
        exp_dir / "valid.loss.best.pth",
        exp_dir / "checkpoint.pth",
    ]
    
    model_file = None
    for mf in model_files:
        if mf.exists():
            model_file = mf
            break
    
    if model_file is None:
        print("âŒ No trained model found")
        print("Available files in exp directory:")
        if exp_dir.exists():
            for f in exp_dir.iterdir():
                if f.suffix == '.pth':
                    print(f"  - {f}")
        return False
    
    print(f"ğŸ“Š Using model: {model_file}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ•°æ®
    test_speech = data_dir / "test" / "speech.scp"
    test_emotion = data_dir / "test" / "emotion.txt"
    
    if not test_speech.exists() or not test_emotion.exists():
        print("âš ï¸  Test data not found, using validation data for evaluation")
        test_speech = data_dir / "valid" / "speech.scp"
        test_emotion = data_dir / "valid" / "emotion.txt"
    
    # ESP-netæ¨ç†å‘½ä»¤
    eval_cmd = [
        sys.executable, "ser_inference.py",
        "--model_file", str(model_file),
        "--valid_data_path_and_name_and_type", f"{test_speech},speech,sound",
        "--valid_data_path_and_name_and_type", f"{test_emotion},emotion,text", 
        "--output_dir", str(exp_dir / "results"),
        "--ngpu", "1",
        "--batch_size", "32",
    ]
    
    print("ğŸ“Š Starting ESP-net evaluation...")
    print("Command:", " ".join(eval_cmd))
    print()
    
    try:
        result = subprocess.run(eval_cmd, check=True, capture_output=False)
        print("âœ… Evaluation completed successfully!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ Evaluation failed with exit code {e.returncode}")
        return False
    except FileNotFoundError as e:
        print(f"âŒ Inference script not found: {e}")
        return False

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("ğŸ“¦ Checking dependencies...")
    
    required_packages = [
        "torch",
        "torchaudio", 
        "transformers",
        "sklearn",
        "numpy",
        "yaml"
    ]
    
    missing = []
    for pkg in required_packages:
        try:
            __import__(pkg.replace("-", "_"))
            print(f"âœ… {pkg}")
        except ImportError:
            missing.append(pkg)
            print(f"âŒ {pkg}")
    
    if missing:
        print(f"\nğŸ”§ Installing missing packages: {missing}")
        subprocess.run([sys.executable, "-m", "pip", "install"] + missing)
    
    # æ£€æŸ¥ESP-net
    try:
        import espnet2
        print("âœ… espnet2")
    except ImportError:
        print("âŒ espnet2 - Installing...")
        subprocess.run([sys.executable, "-m", "pip", "install", "espnet"])

def main():
    parser = argparse.ArgumentParser(description='ESP-net WavLM + ECAPA-TDNN Baseline')
    parser.add_argument('--baseline_dir', type=str, required=True,
                       help='Path to MSP-PODCAST baseline directory')
    parser.add_argument('--stage', type=str, default='all',
                       choices=['data', 'train', 'eval', 'all'],
                       help='Which stage to run')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸµ ESP-net WavLM + ECAPA-TDNN Baseline")
    print("ğŸ¯ Optimized for Macro-F1")
    print("="*60)
    
    # 0. æ£€æŸ¥ä¾èµ–
    print("ğŸ“¦ Step 0: Checking Dependencies")
    check_dependencies()
    
    # 1. è„šæœ¬å‡†å¤‡
    print("\nğŸ”§ Step 1: Script Preparation")
    if not ensure_scripts_exist():
        print("âŒ Script preparation failed")
        sys.exit(1)
    
    # 2. æ•°æ®å‡†å¤‡
    if args.stage in ['data', 'all']:
        print("\nğŸ”§ Step 2: Data Preparation")
        try:
            prepare_espnet_data(args.baseline_dir)
        except Exception as e:
            print(f"âŒ Data preparation failed: {e}")
            if args.stage == 'data':
                sys.exit(1)
    
    # 3. æ¨¡å‹è®­ç»ƒ
    if args.stage in ['train', 'all']:
        print("\nğŸš€ Step 3: Model Training")
        if not run_espnet_training():
            sys.exit(1)
    
    # 4. æ¨¡å‹è¯„ä¼°
    if args.stage in ['eval', 'all']:
        print("\nğŸ“Š Step 4: Model Evaluation")
        if not run_espnet_evaluation():
            print("âš ï¸  Evaluation failed, but training may have succeeded")
    
    print("\n" + "="*60)
    print("ğŸ‰ ESP-net WavLM + ECAPA-TDNN Baseline Completed!")
    print("ğŸ“ Check results in: exp/wavlm_ecapa_baseline/")
    print("ğŸ¯ Focus metric: Macro-F1")
    print("\nğŸ“Š Generated files:")
    print("  - Model checkpoints: exp/wavlm_ecapa_baseline/*.pth")
    print("  - Training logs: exp/wavlm_ecapa_baseline/train.log")
    print("  - TensorBoard logs: exp/wavlm_ecapa_baseline/tensorboard/")
    print("="*60)

if __name__ == "__main__":
    main()