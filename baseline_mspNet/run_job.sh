#!/bin/bash
# run_job.sh - SLURMä½œä¸šè„šæœ¬ï¼ˆäº‘ç«¯é›†ç¾¤ï¼‰

#SBATCH --job-name=wavlm_ecapa_ser
#SBATCH --output=logs/ser_training_%j.out
#SBATCH --error=logs/ser_training_%j.err
#SBATCH --time=48:00:00                    # 48å°æ—¶æ—¶é—´é™åˆ¶
#SBATCH --partition=gpu                    # GPUåˆ†åŒº
#SBATCH --gres=gpu:1                       # è¯·æ±‚1ä¸ªGPU
#SBATCH --cpus-per-task=8                  # 8ä¸ªCPUæ ¸å¿ƒ
#SBATCH --mem=32G                          # 32GBå†…å­˜
#SBATCH --nodes=1                          # å•èŠ‚ç‚¹
#SBATCH --ntasks-per-node=1                # æ¯èŠ‚ç‚¹1ä¸ªä»»åŠ¡

# ============================================================================
# çŽ¯å¢ƒè®¾ç½®
# ============================================================================

echo "ðŸŒ Starting ESP-net SER training on cloud cluster"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_NODELIST"
echo "GPU: $CUDA_VISIBLE_DEVICES"
echo "==============================================="

# è®¾ç½®å·¥ä½œç›®å½•
cd $SLURM_SUBMIT_DIR
echo "Working directory: $(pwd)"

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs

# åŠ è½½å¿…è¦çš„æ¨¡å—ï¼ˆæ ¹æ®ä½ çš„é›†ç¾¤çŽ¯å¢ƒè°ƒæ•´ï¼‰
# module load cuda/11.8
# module load python/3.9
# module load gcc/9.3.0

# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰
# source /path/to/your/venv/bin/activate

# æˆ–è€…ä½¿ç”¨condaçŽ¯å¢ƒ
# conda activate espnet_env

# ============================================================================
# çŽ¯å¢ƒæ£€æŸ¥
# ============================================================================

echo "ðŸ“‹ Environment Information:"
echo "Python version: $(python --version)"
echo "CUDA version: $(nvcc --version 2>/dev/null || echo 'CUDA not found')"
echo "GPU info:"
nvidia-smi || echo "nvidia-smi not available"
echo ""

# æ£€æŸ¥æ•°æ®è·¯å¾„
DATA_ROOT="/data/user_data/esthers/SER_MSP"
echo "ðŸ“Š Checking data paths:"
echo "Data root: $DATA_ROOT"
ls -la $DATA_ROOT/ | head -10

echo "Audio directory:"
ls -la $DATA_ROOT/DATA/Audios/ | head -5
echo "Total audio files: $(find $DATA_ROOT/DATA/Audios/ -name "*.wav" | wc -l)"

echo "JSON files:"
for json_file in msp_train_10class.json msp_valid_10class.json msp_test_10class.json; do
    if [ -f "$DATA_ROOT/$json_file" ]; then
        echo "âœ… $json_file ($(jq '. | length' $DATA_ROOT/$json_file) samples)"
    else
        echo "âŒ $json_file missing"
    fi
done

# ============================================================================
# ä¾èµ–å®‰è£…å’Œæ£€æŸ¥
# ============================================================================

echo ""
echo "ðŸ“¦ Installing/checking dependencies..."

# å®‰è£…ESP-netå’Œä¾èµ–ï¼ˆå¦‚æžœéœ€è¦ï¼‰
pip install --user espnet transformers torch torchaudio scikit-learn pyyaml numpy tqdm

# æ£€æŸ¥å®‰è£…
echo "Checking installations:"
python -c "
try:
    import espnet
    import transformers
    import torch
    import torchaudio
    print('âœ… All major dependencies available')
    print(f'PyTorch: {torch.__version__}')
    print(f'ESP-net: {espnet.__version__}')
    print(f'Transformers: {transformers.__version__}')
    print(f'CUDA available: {torch.cuda.is_available()}')
    if torch.cuda.is_available():
        print(f'GPU device: {torch.cuda.get_device_name(0)}')
        print(f'GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB')
except ImportError as e:
    print(f'âŒ Import error: {e}')
    exit(1)
"

# ============================================================================
# è®­ç»ƒæ‰§è¡Œ
# ============================================================================

echo ""
echo "ðŸš€ Starting ESP-net training..."
echo "Time: $(date)"

# è®¾ç½®çŽ¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0
export OMP_NUM_THREADS=8

# è®°å½•å¼€å§‹æ—¶é—´
start_time=$(date +%s)

# è¿è¡Œè®­ç»ƒè„šæœ¬
python cloud_run.py 2>&1 | tee logs/training_log_${SLURM_JOB_ID}.txt

# æ£€æŸ¥è®­ç»ƒæ˜¯å¦æˆåŠŸ
exit_code=${PIPESTATUS[0]}

# è®°å½•ç»“æŸæ—¶é—´
end_time=$(date +%s)
duration=$((end_time - start_time))
hours=$((duration / 3600))
minutes=$(((duration % 3600) / 60))

echo ""
echo "==============================================="
echo "ðŸ Training completed"
echo "Time: $(date)"
echo "Duration: ${hours}h ${minutes}m"
echo "Exit code: $exit_code"

if [ $exit_code -eq 0 ]; then
    echo "âœ… Training successful!"
    
    # æ˜¾ç¤ºç»“æžœæ¦‚è¦
    echo ""
    echo "ðŸ“Š Results summary:"
    if [ -f "exp/cloud_wavlm_ecapa/train.log" ]; then
        echo "Training log size: $(du -h exp/cloud_wavlm_ecapa/train.log | cut -f1)"
        echo "Last few lines of training log:"
        tail -10 exp/cloud_wavlm_ecapa/train.log
    fi
    
    # æ£€æŸ¥ç”Ÿæˆçš„æ¨¡åž‹æ–‡ä»¶
    if [ -d "exp/cloud_wavlm_ecapa" ]; then
        echo ""
        echo "Generated files:"
        ls -lh exp/cloud_wavlm_ecapa/*.pth 2>/dev/null || echo "No model files found"
    fi
    
else
    echo "âŒ Training failed with exit code $exit_code"
    echo "Check the log file for details: logs/training_log_${SLURM_JOB_ID}.txt"
fi

# ============================================================================
# åŽå¤„ç†å’Œæ¸…ç†
# ============================================================================

# åŽ‹ç¼©æ—¥å¿—æ–‡ä»¶
if [ -f "logs/training_log_${SLURM_JOB_ID}.txt" ]; then
    gzip logs/training_log_${SLURM_JOB_ID}.txt
fi

# ç”Ÿæˆä½œä¸šæŠ¥å‘Š
echo "ðŸ“‹ Job Report:" > job_report_${SLURM_JOB_ID}.txt
echo "Job ID: $SLURM_JOB_ID" >> job_report_${SLURM_JOB_ID}.txt
echo "Node: $SLURM_NODELIST" >> job_report_${SLURM_JOB_ID}.txt
echo "Start time: $(date -d @$start_time)" >> job_report_${SLURM_JOB_ID}.txt
echo "End time: $(date -d @$end_time)" >> job_report_${SLURM_JOB_ID}.txt
echo "Duration: ${hours}h ${minutes}m" >> job_report_${SLURM_JOB_ID}.txt
echo "Exit code: $exit_code" >> job_report_${SLURM_JOB_ID}.txt

if [ $exit_code -eq 0 ]; then
    echo "Status: SUCCESS" >> job_report_${SLURM_JOB_ID}.txt
else
    echo "Status: FAILED" >> job_report_${SLURM_JOB_ID}.txt
fi

echo ""
echo "ðŸ“„ Job report saved: job_report_${SLURM_JOB_ID}.txt"
echo "ðŸŽ‰ Job completed!"

exit $exit_code